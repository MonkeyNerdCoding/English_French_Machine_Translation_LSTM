{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "59b9c404",
      "metadata": {
        "id": "59b9c404"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import spacy\n",
        "import os\n",
        "import random\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1ktXjQ0SRGVT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ktXjQ0SRGVT",
        "outputId": "d61b733d-e316-4fcb-c35b-10d7258766a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "hOeyQvzWzdB8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOeyQvzWzdB8",
        "outputId": "45391589-5bf2-4a93-a65c-ca5a25e14714"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f755dae3",
      "metadata": {
        "id": "f755dae3"
      },
      "outputs": [],
      "source": [
        "# !pip install torch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bd39989",
      "metadata": {
        "id": "6bd39989"
      },
      "source": [
        "# ============================================================================\n",
        "# 1. CHU·∫®N B·ªä D·ªÆ LI·ªÜU\n",
        "# ============================================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "01aa45bd",
      "metadata": {
        "id": "01aa45bd"
      },
      "outputs": [],
      "source": [
        "class Vocabulary:\n",
        "    \"\"\"X√¢y d·ª±ng t·ª´ ƒëi·ªÉn cho m·ªôt ng√¥n ng·ªØ\"\"\"\n",
        "    def __init__(self, max_vocab_size=10000):\n",
        "        self.max_vocab_size = max_vocab_size\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.word_freq = Counter()\n",
        "\n",
        "        # Token ƒë·∫∑c bi·ªát\n",
        "        self.PAD_TOKEN = '<pad>'\n",
        "        self.UNK_TOKEN = '<unk>'\n",
        "        self.SOS_TOKEN = '<sos>'\n",
        "        self.EOS_TOKEN = '<eos>'\n",
        "\n",
        "        self.pad_idx = 0\n",
        "        self.unk_idx = 1\n",
        "        self.sos_idx = 2\n",
        "        self.eos_idx = 3\n",
        "\n",
        "    def build_vocab(self, sentences):\n",
        "        \"\"\"X√¢y d·ª±ng t·ª´ ƒëi·ªÉn t·ª´ danh s√°ch c√¢u\"\"\"\n",
        "        # ƒê·∫øm t·∫ßn su·∫•t t·ª´\n",
        "        for sentence in sentences:\n",
        "            self.word_freq.update(sentence)\n",
        "\n",
        "        # L·∫•y top t·ª´ ph·ªï bi·∫øn\n",
        "        most_common = self.word_freq.most_common(self.max_vocab_size - 4)\n",
        "\n",
        "        # Th√™m token ƒë·∫∑c bi·ªát\n",
        "        self.word2idx = {\n",
        "            self.PAD_TOKEN: self.pad_idx,\n",
        "            self.UNK_TOKEN: self.unk_idx,\n",
        "            self.SOS_TOKEN: self.sos_idx,\n",
        "            self.EOS_TOKEN: self.eos_idx\n",
        "        }\n",
        "\n",
        "        # Th√™m c√°c t·ª´ ph·ªï bi·∫øn\n",
        "        for idx, (word, freq) in enumerate(most_common, start=4):\n",
        "            self.word2idx[word] = idx\n",
        "\n",
        "        # T·∫°o √°nh x·∫° ng∆∞·ª£c\n",
        "        self.idx2word = {idx: word for word, idx in self.word2idx.items()}\n",
        "\n",
        "    def encode(self, sentence):\n",
        "        \"\"\"Chuy·ªÉn c√¢u th√†nh list index\"\"\"\n",
        "        return [self.word2idx.get(word, self.unk_idx) for word in sentence]\n",
        "\n",
        "    def decode(self, indices):\n",
        "        \"\"\"Chuy·ªÉn list index th√†nh c√¢u\"\"\"\n",
        "        return [self.idx2word.get(idx, self.UNK_TOKEN) for idx in indices]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.word2idx)\n",
        "\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    \"\"\"Dataset cho d·ªãch m√°y\"\"\"\n",
        "    def __init__(self, src_sentences, tgt_sentences, src_vocab, tgt_vocab):\n",
        "        self.src_sentences = src_sentences\n",
        "        self.tgt_sentences = tgt_sentences\n",
        "        self.src_vocab = src_vocab\n",
        "        self.tgt_vocab = tgt_vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src = self.src_sentences[idx]\n",
        "        tgt = self.tgt_sentences[idx]\n",
        "\n",
        "        # Encode th√†nh indices\n",
        "        src_indices = self.src_vocab.encode(src) + [self.src_vocab.eos_idx]\n",
        "        tgt_indices = [self.tgt_vocab.sos_idx] + self.tgt_vocab.encode(tgt) + [self.tgt_vocab.eos_idx]\n",
        "\n",
        "        return torch.LongTensor(src_indices), torch.LongTensor(tgt_indices)\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    \"\"\"Collate function ƒë·ªÉ x·ª≠ l√Ω padding v√† sorting\"\"\"\n",
        "    src_batch, tgt_batch = zip(*batch)\n",
        "\n",
        "    # S·∫Øp x·∫øp theo ƒë·ªô d√†i gi·∫£m d·∫ßn (b·∫Øt bu·ªôc cho pack_padded_sequence)\n",
        "    src_lengths = torch.LongTensor([len(s) for s in src_batch])\n",
        "    sorted_indices = src_lengths.argsort(descending=True)\n",
        "\n",
        "    src_batch = [src_batch[i] for i in sorted_indices]\n",
        "    tgt_batch = [tgt_batch[i] for i in sorted_indices]\n",
        "    src_lengths = src_lengths[sorted_indices]\n",
        "\n",
        "    # Padding\n",
        "    src_padded = pad_sequence(src_batch, batch_first=True, padding_value=0)\n",
        "    tgt_padded = pad_sequence(tgt_batch, batch_first=True, padding_value=0)\n",
        "\n",
        "    return src_padded, src_lengths, tgt_padded"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fOlQ54GLBXMD",
      "metadata": {
        "id": "fOlQ54GLBXMD"
      },
      "source": [
        "# ============================================================================\n",
        "# 2. M√î H√åNH ENCODER-DECODER\n",
        "# ============================================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "a85649a7",
      "metadata": {
        "id": "a85649a7"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"\"\"LSTM Encoder\"\"\"\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers, dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers,\n",
        "                           batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src, src_lengths):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            src: (batch_size, src_len)\n",
        "            src_lengths: (batch_size,)\n",
        "        Returns:\n",
        "            hidden: (num_layers, batch_size, hidden_size)\n",
        "            cell: (num_layers, batch_size, hidden_size)\n",
        "        \"\"\"\n",
        "        embedded = self.dropout(self.embedding(src))  # (batch, src_len, emb_dim)\n",
        "\n",
        "        # Pack sequence\n",
        "        packed = pack_padded_sequence(embedded, src_lengths.cpu(), batch_first=True, enforce_sorted=True)\n",
        "\n",
        "        # LSTM\n",
        "        packed_output, (hidden, cell) = self.lstm(packed)\n",
        "\n",
        "        # hidden: (num_layers, batch, hidden_size)\n",
        "        # cell: (num_layers, batch, hidden_size)\n",
        "        return hidden, cell\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"LSTM Decoder\"\"\"\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers, dropout):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers,\n",
        "                           batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
        "        self.fc_out = nn.Linear(hidden_size, vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input_token, hidden, cell):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input_token: (batch_size, 1)\n",
        "            hidden: (num_layers, batch_size, hidden_size)\n",
        "            cell: (num_layers, batch_size, hidden_size)\n",
        "        Returns:\n",
        "            prediction: (batch_size, vocab_size)\n",
        "            hidden: (num_layers, batch_size, hidden_size)\n",
        "            cell: (num_layers, batch_size, hidden_size)\n",
        "        \"\"\"\n",
        "        embedded = self.dropout(self.embedding(input_token))  # (batch, 1, emb_dim)\n",
        "\n",
        "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
        "        # output: (batch, 1, hidden_size)\n",
        "\n",
        "        prediction = self.fc_out(output.squeeze(1))  # (batch, vocab_size)\n",
        "\n",
        "        return prediction, hidden, cell\n",
        "\n",
        "\n",
        "# Thay th·∫ø class Seq2Seq.forward b·∫±ng ƒëo·∫°n n√†y\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, src_lengths, tgt, teacher_forcing_ratio=0.5):\n",
        "        batch_size = src.shape[0]\n",
        "        tgt_len = tgt.shape[1]\n",
        "        tgt_vocab_size = self.decoder.vocab_size\n",
        "\n",
        "        outputs = torch.zeros(batch_size, tgt_len, tgt_vocab_size).to(self.device)\n",
        "\n",
        "        # Encoder\n",
        "        hidden, cell = self.encoder(src, src_lengths)\n",
        "\n",
        "        # N·∫øu d√πng full teacher forcing -> vectorized decoding (1 pass LSTM)\n",
        "        if teacher_forcing_ratio >= 1.0 - 1e-9:\n",
        "            # Input to decoder LSTM are the target tokens excluding the last token\n",
        "            # (we use targets as inputs when teacher forcing)\n",
        "            # tgt_in: shape (batch, tgt_len-1)\n",
        "            tgt_in = tgt[:, :-1]  # exclude final <eos> if present\n",
        "            embedded = self.decoder.embedding(tgt_in)  # (batch, seq_len, emb_dim)\n",
        "            embedded = self.decoder.dropout(embedded)\n",
        "\n",
        "            # Run decoder LSTM once for the whole sequence\n",
        "            decoder_outputs, (hidden, cell) = self.decoder.lstm(embedded, (hidden, cell))\n",
        "            # decoder_outputs: (batch, seq_len, hidden_size)\n",
        "            # Map to vocab\n",
        "            pred = self.decoder.fc_out(decoder_outputs)  # (batch, seq_len, vocab_size)\n",
        "\n",
        "            # Place predictions into outputs aligned so that outputs[:, t, :] predicts token at tgt[:, t]\n",
        "            outputs[:, 1:tgt_len, :] = pred  # note: pred corresponds to steps 1..tgt_len-1\n",
        "            # (outputs[:,0,:] stays zeros or you can set it to prediction for <sos> if you want)\n",
        "            return outputs\n",
        "\n",
        "        # Fallback: mixed or no teacher forcing -> step-by-step (c≈©)\n",
        "        decoder_input = tgt[:, 0].unsqueeze(1)  # <sos>\n",
        "        for t in range(1, tgt_len):\n",
        "            prediction, hidden, cell = self.decoder(decoder_input, hidden, cell)\n",
        "            outputs[:, t, :] = prediction\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = prediction.argmax(1).unsqueeze(1)\n",
        "            decoder_input = tgt[:, t].unsqueeze(1) if teacher_force else top1\n",
        "\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4007c696",
      "metadata": {
        "id": "4007c696"
      },
      "source": [
        "# ============================================================================\n",
        "# 3. HU·∫§N LUY·ªÜN\n",
        "# ============================================================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "49dab472",
      "metadata": {
        "id": "49dab472"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, dataloader, optimizer, criterion, clip, device):\n",
        "    \"\"\"Hu·∫•n luy·ªán 1 epoch\"\"\"\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for src, src_lengths, tgt in dataloader:\n",
        "        src = src.to(device)\n",
        "        tgt = tgt.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward\n",
        "        output = model(src, src_lengths, tgt, teacher_forcing_ratio=0.5)\n",
        "\n",
        "        # output: (batch, tgt_len, vocab_size)\n",
        "        # tgt: (batch, tgt_len)\n",
        "\n",
        "        # B·ªè <sos> token v√† flatten\n",
        "        output = output[:, 1:, :].reshape(-1, output.shape[-1])\n",
        "        tgt = tgt[:, 1:].reshape(-1)\n",
        "\n",
        "        # T√≠nh loss\n",
        "        loss = criterion(output, tgt)\n",
        "\n",
        "        # Backward\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(dataloader)\n",
        "\n",
        "\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    \"\"\"ƒê√°nh gi√° tr√™n t·∫≠p validation\"\"\"\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src, src_lengths, tgt in dataloader:\n",
        "            src = src.to(device)\n",
        "            tgt = tgt.to(device)\n",
        "\n",
        "            # Forward (kh√¥ng teacher forcing)\n",
        "            output = model(src, src_lengths, tgt, teacher_forcing_ratio=0)\n",
        "\n",
        "            output = output[:, 1:, :].reshape(-1, output.shape[-1])\n",
        "            tgt = tgt[:, 1:].reshape(-1)\n",
        "\n",
        "            loss = criterion(output, tgt)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9377802",
      "metadata": {
        "id": "e9377802"
      },
      "source": [
        "# ============================================================================\n",
        "# 4. D·ª∞ ƒêO√ÅN (INFERENCE)\n",
        "# ============================================================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "801b4f7f",
      "metadata": {
        "id": "801b4f7f"
      },
      "outputs": [],
      "source": [
        "def translate_sentence(model, sentence, src_vocab, tgt_vocab, src_tokenizer, device, max_len=50):\n",
        "    \"\"\"\n",
        "    D·ªãch m·ªôt c√¢u t·ª´ ti·∫øng Anh sang ti·∫øng Ph√°p\n",
        "\n",
        "    Args:\n",
        "        model: m√¥ h√¨nh ƒë√£ train\n",
        "        sentence: c√¢u ti·∫øng Anh (string)\n",
        "        src_vocab, tgt_vocab: t·ª´ ƒëi·ªÉn\n",
        "        src_tokenizer: tokenizer cho ti·∫øng Anh\n",
        "        device: cuda/cpu\n",
        "        max_len: ƒë·ªô d√†i t·ªëi ƒëa c√¢u d·ªãch\n",
        "\n",
        "    Returns:\n",
        "        translated_sentence: c√¢u ti·∫øng Ph√°p (string)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Tokenize\n",
        "    tokens = src_tokenizer(sentence.lower())\n",
        "    tokens = [token.text for token in tokens]\n",
        "\n",
        "    # Encode\n",
        "    indices = src_vocab.encode(tokens) + [src_vocab.eos_idx]\n",
        "    src_tensor = torch.LongTensor(indices).unsqueeze(0).to(device)  # (1, src_len)\n",
        "    src_lengths = torch.LongTensor([len(indices)])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Encoder\n",
        "        hidden, cell = model.encoder(src_tensor, src_lengths)\n",
        "\n",
        "        # Decoder\n",
        "        decoder_input = torch.LongTensor([tgt_vocab.sos_idx]).unsqueeze(0).to(device)\n",
        "        translated_indices = []\n",
        "\n",
        "        for _ in range(max_len):\n",
        "            prediction, hidden, cell = model.decoder(decoder_input, hidden, cell)\n",
        "            predicted_token = prediction.argmax(1).item()\n",
        "\n",
        "            if predicted_token == tgt_vocab.eos_idx:\n",
        "                break\n",
        "\n",
        "            translated_indices.append(predicted_token)\n",
        "            decoder_input = torch.LongTensor([predicted_token]).unsqueeze(0).to(device)\n",
        "\n",
        "    # Decode\n",
        "    translated_tokens = tgt_vocab.decode(translated_indices)\n",
        "    translated_sentence = ' '.join(translated_tokens)\n",
        "\n",
        "    return translated_sentence\n",
        "\n",
        "\n",
        "def calculate_bleu(model, test_data, src_vocab, tgt_vocab, src_tokenizer, device):\n",
        "    \"\"\"T√≠nh BLEU score tr√™n t·∫≠p test\"\"\"\n",
        "    bleu_scores = []\n",
        "    smoothing = SmoothingFunction().method1\n",
        "\n",
        "    for src_sent, tgt_sent in test_data:\n",
        "        src_text = ' '.join(src_sent)\n",
        "        translated = translate_sentence(model, src_text, src_vocab, tgt_vocab, src_tokenizer, device)\n",
        "\n",
        "        reference = [tgt_sent]\n",
        "        candidate = translated.split()\n",
        "\n",
        "        score = sentence_bleu(reference, candidate, smoothing_function=smoothing)\n",
        "        bleu_scores.append(score)\n",
        "\n",
        "    return np.mean(bleu_scores)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ce7a31f",
      "metadata": {
        "id": "8ce7a31f"
      },
      "source": [
        "# ============================================================================\n",
        "# 5. MAIN - S·ª¨ D·ª§NG\n",
        "# ============================================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d113f40b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d113f40b",
        "outputId": "b8df01d9-8ebf-4e36-ec6f-2581179a076f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: fr_core_news_sm not found. Using spacy.blank('fr'). Please install with !python -m spacy download fr_core_news_sm\n",
            "Tokenizing...\n",
            "Building vocabularies...\n",
            "Train examples: 29000\n",
            "Val examples: 1014\n",
            "Test examples: 1071\n",
            "Example tokenized (src -> tgt):\n",
            "['two', 'young', ',', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']\n",
            "['deux', 'jeunes', 'hommes', 'blancs', 'sont', 'dehors', 'pr√®s', 'de', 'buissons', '.']\n",
            "Epoch 1/10\n",
            "Train Loss: 4.904 | Val Loss: 4.645\n",
            "Epoch 2/10\n",
            "Train Loss: 3.993 | Val Loss: 4.313\n",
            "Epoch 3/10\n",
            "Train Loss: 3.600 | Val Loss: 4.093\n",
            "Epoch 4/10\n",
            "Train Loss: 3.306 | Val Loss: 3.964\n",
            "Epoch 5/10\n",
            "Train Loss: 3.075 | Val Loss: 3.866\n",
            "Epoch 6/10\n",
            "Train Loss: 2.893 | Val Loss: 3.752\n",
            "Epoch 7/10\n",
            "Train Loss: 2.724 | Val Loss: 3.695\n",
            "Epoch 8/10\n",
            "Train Loss: 2.610 | Val Loss: 3.681\n",
            "Epoch 9/10\n",
            "Train Loss: 2.462 | Val Loss: 3.688\n",
            "Epoch 10/10\n",
            "Train Loss: 2.362 | Val Loss: 3.593\n",
            "BLEU Score: 0.1221\n"
          ]
        }
      ],
      "source": [
        "# Removed the main() function definition and moved the code outside\n",
        "# This makes the variables (model, vocabularies, tokenizer, device, etc.) available globally.\n",
        "\n",
        "# C·∫•u h√¨nh\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyperparameters\n",
        "EMBEDDING_DIM = 256\n",
        "HIDDEN_SIZE = 512\n",
        "NUM_LAYERS = 2\n",
        "DROPOUT = 0.5\n",
        "LEARNING_RATE = 0.001\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "# -- ƒê∆∞·ªùng d·∫´n t·ªõi th∆∞ m·ª•c d·ªØ li·ªáu (t∆∞∆°ng ƒë·ªëi v·ªõi notebook) --\n",
        "data_dir = '/content/'\n",
        "\n",
        "def load_lines(path):\n",
        "    \"\"\"ƒê·ªçc file v√† tr·∫£ v·ªÅ danh s√°ch d√≤ng (kh√¥ng tokenized)\"\"\"\n",
        "    lines = []\n",
        "    with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line:\n",
        "                lines.append(line)\n",
        "    return lines\n",
        "\n",
        "\n",
        "def tokenize_lines(lines, tokenizer):\n",
        "    \"\"\"Tokenize danh s√°ch c√¢u tr·∫£ v·ªÅ list of token lists\"\"\"\n",
        "    tokenized = []\n",
        "    for line in lines:\n",
        "        toks = [t.text for t in tokenizer(line.lower()) if t.text.strip()]\n",
        "        tokenized.append(toks)\n",
        "    return tokenized\n",
        "\n",
        "# T·∫≠p tin theo c·∫•u tr√∫c workspace: dataset/<split>/(file)\n",
        "train_en_path = os.path.join(data_dir, 'train.en')\n",
        "train_fr_path = os.path.join(data_dir, 'train.fr')\n",
        "val_en_path = os.path.join(data_dir, 'val.en')\n",
        "val_fr_path = os.path.join(data_dir, 'val.fr')\n",
        "test_en_path = os.path.join(data_dir, 'test_2018_flickr.en')\n",
        "test_fr_path = os.path.join(data_dir, 'test_2018_flickr.fr')\n",
        "\n",
        "\n",
        "# Load raw lines\n",
        "train_en_lines = load_lines(train_en_path)\n",
        "train_fr_lines = load_lines(train_fr_path)\n",
        "val_en_lines = load_lines(val_en_path)\n",
        "val_fr_lines = load_lines(val_fr_path)\n",
        "test_en_lines = load_lines(test_en_path)\n",
        "test_fr_lines = load_lines(test_fr_path)\n",
        "\n",
        "# Tokenizers: th·ª≠ load spacy models, fallback sang spacy.blank n·∫øu model ch∆∞a c√†i\n",
        "try:\n",
        "    en_tokenizer = spacy.load('en_core_web_sm')\n",
        "except Exception:\n",
        "    # N·∫øu model en_core_web_sm ch∆∞a c√†i, d√πng blank tokenizer (ƒë∆°n gi·∫£n)\n",
        "    print(\"Warning: en_core_web_sm not found. Using spacy.blank('en'). Please install with !python -m spacy download en_core_web_sm\")\n",
        "    en_tokenizer = spacy.blank('en')\n",
        "\n",
        "try:\n",
        "    fr_tokenizer = spacy.load('fr_core_news_sm')\n",
        "except Exception:\n",
        "    print(\"Warning: fr_core_news_sm not found. Using spacy.blank('fr'). Please install with !python -m spacy download fr_core_news_sm\")\n",
        "    fr_tokenizer = spacy.blank('fr')\n",
        "\n",
        "\n",
        "# Tokenize t·∫•t c·∫£\n",
        "print('Tokenizing...')\n",
        "train_en_tok = tokenize_lines(train_en_lines, en_tokenizer)\n",
        "train_fr_tok = tokenize_lines(train_fr_lines, fr_tokenizer)\n",
        "val_en_tok = tokenize_lines(val_en_lines, en_tokenizer)\n",
        "val_fr_tok = tokenize_lines(val_fr_lines, fr_tokenizer)\n",
        "test_en_tok = tokenize_lines(test_en_lines, en_tokenizer)\n",
        "test_fr_tok = tokenize_lines(test_fr_lines, fr_tokenizer)\n",
        "\n",
        "# Build vocabularies (t·ª´ train set)\n",
        "print('Building vocabularies...')\n",
        "src_vocab = Vocabulary(max_vocab_size=10000)\n",
        "src_vocab.build_vocab(train_en_tok)\n",
        "tgt_vocab = Vocabulary(max_vocab_size=10000)\n",
        "tgt_vocab.build_vocab(train_fr_tok)\n",
        "\n",
        "# T·∫°o Dataset v√† DataLoader\n",
        "train_dataset = TranslationDataset(train_en_tok, train_fr_tok, src_vocab, tgt_vocab)\n",
        "val_dataset = TranslationDataset(val_en_tok, val_fr_tok, src_vocab, tgt_vocab)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "# test_data d√πng cho calculate_bleu (d·∫°ng list of (src_tokens, tgt_tokens))\n",
        "test_data = list(zip(test_en_tok, test_fr_tok))\n",
        "\n",
        "# Sanity prints\n",
        "print(f'Train examples: {len(train_dataset)}')\n",
        "print(f'Val examples: {len(val_dataset)}')\n",
        "print(f'Test examples: {len(test_data)}')\n",
        "print('Example tokenized (src -> tgt):')\n",
        "print(train_en_tok[0][:20])\n",
        "print(train_fr_tok[0][:20])\n",
        "\n",
        "# Kh·ªüi t·∫°o m√¥ h√¨nh (d√πng k√≠ch th∆∞·ªõc t·ª´ vocab ƒë√£ t·∫°o)\n",
        "encoder = Encoder(len(src_vocab), EMBEDDING_DIM, HIDDEN_SIZE, NUM_LAYERS, DROPOUT)\n",
        "decoder = Decoder(len(tgt_vocab), EMBEDDING_DIM, HIDDEN_SIZE, NUM_LAYERS, DROPOUT)\n",
        "model = Seq2Seq(encoder, decoder, device).to(device)\n",
        "\n",
        "# Optimizer v√† loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "# Use ignore_index for PAD_TOKEN in CrossEntropyLoss\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=tgt_vocab.pad_idx)\n",
        "\n",
        "\n",
        "# (Ph·∫ßn training v·∫´n nh∆∞ c≈©)\n",
        "best_val_loss = float('inf')\n",
        "patience = 3\n",
        "patience_counter = 0\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, criterion, CLIP, device)\n",
        "    val_loss = evaluate(model, val_loader, criterion, device)\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{NUM_EPOCHS}')\n",
        "    print(f'Train Loss: {train_loss:.3f} | Val Loss: {val_loss:.3f}')\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        patience_counter = 0\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(\"Early stopping!\")\n",
        "            break\n",
        "\n",
        "bleu_score = calculate_bleu(model, test_data, src_vocab, tgt_vocab, en_tokenizer, device)\n",
        "print(f'BLEU Score: {bleu_score:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "27d041dc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import spacy\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "22219cc9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "EMBEDDING_DIM = 256\n",
        "HIDDEN_SIZE = 512\n",
        "NUM_LAYERS = 2\n",
        "DROPOUT = 0.5\n",
        "LEARNING_RATE = 0.001\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 10\n",
        "CLIP = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "c3e77587",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úî True - d:\\HK7NAM4\\LTSM\\English_French_Machine_Translation_LSTM\\dataset\\train.en\\train.en\n",
            "‚úî True - d:\\HK7NAM4\\LTSM\\English_French_Machine_Translation_LSTM\\dataset\\train.fr\\train.fr\n",
            "‚úî True - d:\\HK7NAM4\\LTSM\\English_French_Machine_Translation_LSTM\\dataset\\val.en\\val.en\n",
            "‚úî True - d:\\HK7NAM4\\LTSM\\English_French_Machine_Translation_LSTM\\dataset\\val.fr\\val.fr\n",
            "‚úî True - d:\\HK7NAM4\\LTSM\\English_French_Machine_Translation_LSTM\\dataset\\test_2018_flickr.en\\test_2018_flickr.en\n",
            "‚úî True - d:\\HK7NAM4\\LTSM\\English_French_Machine_Translation_LSTM\\dataset\\test_2018_flickr.fr\\test_2018_flickr.fr\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# ‚öôÔ∏è Base folder ch·ª©a c√°c subfolder train.en/, train.fr/, ...\n",
        "data_dir = os.path.join(os.getcwd(), \"dataset\")\n",
        "\n",
        "# üëâ ƒê∆∞·ªùng d·∫´n ch√≠nh x√°c t·ªõi t·ª´ng file th·∫≠t (v√¨ m·ªói file n·∫±m trong folder c√πng t√™n)\n",
        "train_en_path = os.path.join(data_dir, \"train.en\", \"train.en\")\n",
        "train_fr_path = os.path.join(data_dir, \"train.fr\", \"train.fr\")\n",
        "val_en_path = os.path.join(data_dir, \"val.en\", \"val.en\")\n",
        "val_fr_path = os.path.join(data_dir, \"val.fr\", \"val.fr\")\n",
        "test_en_path = os.path.join(data_dir, \"test_2018_flickr.en\", \"test_2018_flickr.en\")\n",
        "test_fr_path = os.path.join(data_dir, \"test_2018_flickr.fr\", \"test_2018_flickr.fr\")\n",
        "\n",
        "# ‚úÖ Ki·ªÉm tra nhanh\n",
        "for path in [train_en_path, train_fr_path, val_en_path, val_fr_path, test_en_path, test_fr_path]:\n",
        "    print(\"‚úî\", os.path.exists(path), \"-\", path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "50958b6a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üßæ Checking dataset files in: d:\\HK7NAM4\\LTSM\\English_French_Machine_Translation_LSTM\\dataset\n",
            " - test_2018_flickr.en\n",
            " - test_2018_flickr.fr\n",
            " - train.en\n",
            " - train.fr\n",
            " - val.en\n",
            " - val.fr\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "print(\"üßæ Checking dataset files in:\", data_dir)\n",
        "for f in glob.glob(os.path.join(data_dir, \"*.*\")):\n",
        "    print(\" -\", os.path.basename(f))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "5bea4515",
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_lines(path):\n",
        "    \"\"\"ƒê·ªçc file v√† tr·∫£ v·ªÅ danh s√°ch d√≤ng (kh√¥ng tokenized).\"\"\"\n",
        "    lines = []\n",
        "    with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line:\n",
        "                lines.append(line)\n",
        "    return lines\n",
        "\n",
        "\n",
        "def tokenize_lines(lines, tokenizer):\n",
        "    \"\"\"Tokenize danh s√°ch c√¢u tr·∫£ v·ªÅ list of token lists.\"\"\"\n",
        "    tokenized = []\n",
        "    for line in lines:\n",
        "        toks = [t.text for t in tokenizer(line.lower()) if t.text.strip()]\n",
        "        tokenized.append(toks)\n",
        "    return tokenized\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "4147f64b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Loaded datasets | Train: 29000 | Val: 1014 | Test: 1071\n"
          ]
        }
      ],
      "source": [
        "train_en_path = os.path.join(data_dir, \"train.en\", \"train.en\")\n",
        "train_fr_path = os.path.join(data_dir, \"train.fr\", \"train.fr\")\n",
        "val_en_path = os.path.join(data_dir, \"val.en\", \"val.en\")\n",
        "val_fr_path = os.path.join(data_dir, \"val.fr\", \"val.fr\")\n",
        "test_en_path = os.path.join(data_dir, \"test_2018_flickr.en\", \"test_2018_flickr.en\")\n",
        "test_fr_path = os.path.join(data_dir, \"test_2018_flickr.fr\", \"test_2018_flickr.fr\")\n",
        "\n",
        "train_en_lines = load_lines(train_en_path)\n",
        "train_fr_lines = load_lines(train_fr_path)\n",
        "val_en_lines = load_lines(val_en_path)\n",
        "val_fr_lines = load_lines(val_fr_path)\n",
        "test_en_lines = load_lines(test_en_path)\n",
        "test_fr_lines = load_lines(test_fr_path)\n",
        "\n",
        "print(f\"‚úÖ Loaded datasets | Train: {len(train_en_lines)} | Val: {len(val_en_lines)} | Test: {len(test_en_lines)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "e5cfbe42",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è en_core_web_sm not found ‚Üí using spacy.blank('en')\n",
            "‚ö†Ô∏è fr_core_news_sm not found ‚Üí using spacy.blank('fr')\n",
            "‚úÖ Tokenizers loaded successfully!\n",
            "‚úÖ Tokenizers loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    en_tokenizer = spacy.load('en_core_web_sm')\n",
        "except Exception:\n",
        "    print(\"‚ö†Ô∏è en_core_web_sm not found ‚Üí using spacy.blank('en')\")\n",
        "    en_tokenizer = spacy.blank('en')\n",
        "\n",
        "try:\n",
        "    fr_tokenizer = spacy.load('fr_core_news_sm')\n",
        "except Exception:\n",
        "    print(\"‚ö†Ô∏è fr_core_news_sm not found ‚Üí using spacy.blank('fr')\")\n",
        "    fr_tokenizer = spacy.blank('fr')\n",
        "\n",
        "print(\"‚úÖ Tokenizers loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "86231801",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üî† Tokenizing data...\n",
            "‚úÖ Tokenized 29000 training examples.\n",
            "‚úÖ Tokenized 29000 training examples.\n"
          ]
        }
      ],
      "source": [
        "print(\"üî† Tokenizing data...\")\n",
        "\n",
        "train_en_tok = tokenize_lines(train_en_lines, en_tokenizer)\n",
        "train_fr_tok = tokenize_lines(train_fr_lines, fr_tokenizer)\n",
        "val_en_tok = tokenize_lines(val_en_lines, en_tokenizer)\n",
        "val_fr_tok = tokenize_lines(val_fr_lines, fr_tokenizer)\n",
        "test_en_tok = tokenize_lines(test_en_lines, en_tokenizer)\n",
        "test_fr_tok = tokenize_lines(test_fr_lines, fr_tokenizer)\n",
        "\n",
        "print(f\"‚úÖ Tokenized {len(train_en_tok)} training examples.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "07aff78d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß± Building vocabularies...\n",
            "Train examples: 29000 | Val examples: 1014 | Test examples: 1071\n",
            "üîç Example: ['two', 'young', ',', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes'] ‚Üí ['deux', 'jeunes', 'hommes', 'blancs', 'sont', 'dehors', 'pr√®s', 'de', 'buissons', '.']\n"
          ]
        }
      ],
      "source": [
        "print(\"üß± Building vocabularies...\")\n",
        "src_vocab = Vocabulary(max_vocab_size=10000)\n",
        "src_vocab.build_vocab(train_en_tok)\n",
        "tgt_vocab = Vocabulary(max_vocab_size=10000)\n",
        "tgt_vocab.build_vocab(train_fr_tok)\n",
        "\n",
        "train_dataset = TranslationDataset(train_en_tok, train_fr_tok, src_vocab, tgt_vocab)\n",
        "val_dataset = TranslationDataset(val_en_tok, val_fr_tok, src_vocab, tgt_vocab)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "test_data = list(zip(test_en_tok, test_fr_tok))\n",
        "\n",
        "print(f\"Train examples: {len(train_dataset)} | Val examples: {len(val_dataset)} | Test examples: {len(test_data)}\")\n",
        "print(\"üîç Example:\", train_en_tok[0][:10], \"‚Üí\", train_fr_tok[0][:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "a0d8afb0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Model initialized successfully!\n"
          ]
        }
      ],
      "source": [
        "encoder = Encoder(len(src_vocab), EMBEDDING_DIM, HIDDEN_SIZE, NUM_LAYERS, DROPOUT)\n",
        "decoder = Decoder(len(tgt_vocab), EMBEDDING_DIM, HIDDEN_SIZE, NUM_LAYERS, DROPOUT)\n",
        "model = Seq2Seq(encoder, decoder, device).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=tgt_vocab.pad_idx)\n",
        "\n",
        "print(\"‚úÖ Model initialized successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abd5db45",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 [Training]:  15%|‚ñà‚ñå        | 69/454 [02:42<14:46,  2.30s/it, loss=5.29]"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# (Ph·∫ßn training v·∫´n nh∆∞ c≈©, ch·ªâ th√™m progress bar)\n",
        "best_val_loss = float('inf')\n",
        "patience = 3\n",
        "patience_counter = 0\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    # progress bar cho train_loader\n",
        "    progress = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Training]\", leave=False)\n",
        "\n",
        "    for batch in progress:\n",
        "        # gi·ªØ nguy√™n c√°ch train_epoch c≈©\n",
        "        loss = train_epoch(model, [batch], optimizer, criterion, CLIP, device)\n",
        "        epoch_loss += loss\n",
        "        progress.set_postfix(loss=loss)\n",
        "\n",
        "    train_loss = epoch_loss / len(train_loader)\n",
        "    val_loss = evaluate(model, val_loader, criterion, device)\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{NUM_EPOCHS}')\n",
        "    print(f'Train Loss: {train_loss:.3f} | Val Loss: {val_loss:.3f}')\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        patience_counter = 0\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(\"Early stopping!\")\n",
        "            break\n",
        "\n",
        "bleu_score = calculate_bleu(model, test_data, src_vocab, tgt_vocab, en_tokenizer, device)\n",
        "print(f'BLEU Score: {bleu_score:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "bW4znrDsw5c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bW4znrDsw5c8",
        "outputId": "169a30da-8db1-472c-afcf-8a66bd6966e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English:  A man is riding a horse.\n",
            "French: un homme fait une cheval .\n"
          ]
        }
      ],
      "source": [
        "sentence = \" A man is riding a horse.\"\n",
        "translation = translate_sentence(model, sentence, src_vocab, tgt_vocab, en_tokenizer, device)\n",
        "print(f'English: {sentence}')\n",
        "print(f'French: {translation}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Mh3VsH4KZINW",
      "metadata": {
        "id": "Mh3VsH4KZINW"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (.venv)",
      "language": "python",
      "name": ".venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
