{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59b9c404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import spacy\n",
    "import random\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd39989",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# 1. CHUẨN BỊ DỮ LIỆU\n",
    "# ============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aa45bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Vocabulary:\n",
    "    \"\"\"Xây dựng từ điển cho một ngôn ngữ\"\"\"\n",
    "    def __init__(self, max_vocab_size=10000):\n",
    "        self.max_vocab_size = max_vocab_size\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.word_freq = Counter()\n",
    "        \n",
    "        # Token đặc biệt\n",
    "        self.PAD_TOKEN = '<pad>'\n",
    "        self.UNK_TOKEN = '<unk>'\n",
    "        self.SOS_TOKEN = '<sos>'\n",
    "        self.EOS_TOKEN = '<eos>'\n",
    "        \n",
    "        self.pad_idx = 0\n",
    "        self.unk_idx = 1\n",
    "        self.sos_idx = 2\n",
    "        self.eos_idx = 3\n",
    "        \n",
    "    def build_vocab(self, sentences):\n",
    "        \"\"\"Xây dựng từ điển từ danh sách câu\"\"\"\n",
    "        # Đếm tần suất từ\n",
    "        for sentence in sentences:\n",
    "            self.word_freq.update(sentence)\n",
    "        \n",
    "        # Lấy top từ phổ biến\n",
    "        most_common = self.word_freq.most_common(self.max_vocab_size - 4)\n",
    "        \n",
    "        # Thêm token đặc biệt\n",
    "        self.word2idx = {\n",
    "            self.PAD_TOKEN: self.pad_idx,\n",
    "            self.UNK_TOKEN: self.unk_idx,\n",
    "            self.SOS_TOKEN: self.sos_idx,\n",
    "            self.EOS_TOKEN: self.eos_idx\n",
    "        }\n",
    "        \n",
    "        # Thêm các từ phổ biến\n",
    "        for idx, (word, freq) in enumerate(most_common, start=4):\n",
    "            self.word2idx[word] = idx\n",
    "        \n",
    "        # Tạo ánh xạ ngược\n",
    "        self.idx2word = {idx: word for word, idx in self.word2idx.items()}\n",
    "        \n",
    "    def encode(self, sentence):\n",
    "        \"\"\"Chuyển câu thành list index\"\"\"\n",
    "        return [self.word2idx.get(word, self.unk_idx) for word in sentence]\n",
    "    \n",
    "    def decode(self, indices):\n",
    "        \"\"\"Chuyển list index thành câu\"\"\"\n",
    "        return [self.idx2word.get(idx, self.UNK_TOKEN) for idx in indices]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.word2idx)\n",
    "\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    \"\"\"Dataset cho dịch máy\"\"\"\n",
    "    def __init__(self, src_sentences, tgt_sentences, src_vocab, tgt_vocab):\n",
    "        self.src_sentences = src_sentences\n",
    "        self.tgt_sentences = tgt_sentences\n",
    "        self.src_vocab = src_vocab\n",
    "        self.tgt_vocab = tgt_vocab\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.src_sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        src = self.src_sentences[idx]\n",
    "        tgt = self.tgt_sentences[idx]\n",
    "        \n",
    "        # Encode thành indices\n",
    "        src_indices = self.src_vocab.encode(src) + [self.src_vocab.eos_idx]\n",
    "        tgt_indices = [self.tgt_vocab.sos_idx] + self.tgt_vocab.encode(tgt) + [self.tgt_vocab.eos_idx]\n",
    "        \n",
    "        return torch.LongTensor(src_indices), torch.LongTensor(tgt_indices)\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Collate function để xử lý padding và sorting\"\"\"\n",
    "    src_batch, tgt_batch = zip(*batch)\n",
    "    \n",
    "    # Sắp xếp theo độ dài giảm dần (bắt buộc cho pack_padded_sequence)\n",
    "    src_lengths = torch.LongTensor([len(s) for s in src_batch])\n",
    "    sorted_indices = src_lengths.argsort(descending=True)\n",
    "    \n",
    "    src_batch = [src_batch[i] for i in sorted_indices]\n",
    "    tgt_batch = [tgt_batch[i] for i in sorted_indices]\n",
    "    src_lengths = src_lengths[sorted_indices]\n",
    "    \n",
    "    # Padding\n",
    "    src_padded = pad_sequence(src_batch, batch_first=True, padding_value=0)\n",
    "    tgt_padded = pad_sequence(tgt_batch, batch_first=True, padding_value=0)\n",
    "    \n",
    "    return src_padded, src_lengths, tgt_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ad9910",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# 2. MÔ HÌNH ENCODER-DECODER\n",
    "# ============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a85649a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"LSTM Encoder\"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, \n",
    "                           batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src, src_lengths):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: (batch_size, src_len)\n",
    "            src_lengths: (batch_size,)\n",
    "        Returns:\n",
    "            hidden: (num_layers, batch_size, hidden_size)\n",
    "            cell: (num_layers, batch_size, hidden_size)\n",
    "        \"\"\"\n",
    "        embedded = self.dropout(self.embedding(src))  # (batch, src_len, emb_dim)\n",
    "        \n",
    "        # Pack sequence\n",
    "        packed = pack_padded_sequence(embedded, src_lengths.cpu(), batch_first=True, enforce_sorted=True)\n",
    "        \n",
    "        # LSTM\n",
    "        packed_output, (hidden, cell) = self.lstm(packed)\n",
    "        \n",
    "        # hidden: (num_layers, batch, hidden_size)\n",
    "        # cell: (num_layers, batch, hidden_size)\n",
    "        return hidden, cell\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"LSTM Decoder\"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers, dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, \n",
    "                           batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "        self.fc_out = nn.Linear(hidden_size, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input_token, hidden, cell):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_token: (batch_size, 1)\n",
    "            hidden: (num_layers, batch_size, hidden_size)\n",
    "            cell: (num_layers, batch_size, hidden_size)\n",
    "        Returns:\n",
    "            prediction: (batch_size, vocab_size)\n",
    "            hidden: (num_layers, batch_size, hidden_size)\n",
    "            cell: (num_layers, batch_size, hidden_size)\n",
    "        \"\"\"\n",
    "        embedded = self.dropout(self.embedding(input_token))  # (batch, 1, emb_dim)\n",
    "        \n",
    "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        # output: (batch, 1, hidden_size)\n",
    "        \n",
    "        prediction = self.fc_out(output.squeeze(1))  # (batch, vocab_size)\n",
    "        \n",
    "        return prediction, hidden, cell\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    \"\"\"Mô hình Encoder-Decoder hoàn chỉnh\"\"\"\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, src, src_lengths, tgt, teacher_forcing_ratio=0.5):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: (batch_size, src_len)\n",
    "            src_lengths: (batch_size,)\n",
    "            tgt: (batch_size, tgt_len)\n",
    "            teacher_forcing_ratio: xác suất dùng ground truth\n",
    "        Returns:\n",
    "            outputs: (batch_size, tgt_len, vocab_size)\n",
    "        \"\"\"\n",
    "        batch_size = src.shape[0]\n",
    "        tgt_len = tgt.shape[1]\n",
    "        tgt_vocab_size = self.decoder.vocab_size\n",
    "        \n",
    "        # Tensor lưu output\n",
    "        outputs = torch.zeros(batch_size, tgt_len, tgt_vocab_size).to(self.device)\n",
    "        \n",
    "        # Encoder\n",
    "        hidden, cell = self.encoder(src, src_lengths)\n",
    "        \n",
    "        # Input đầu tiên của decoder là <sos>\n",
    "        decoder_input = tgt[:, 0].unsqueeze(1)  # (batch, 1)\n",
    "        \n",
    "        # Decode từng time step\n",
    "        for t in range(1, tgt_len):\n",
    "            prediction, hidden, cell = self.decoder(decoder_input, hidden, cell)\n",
    "            outputs[:, t, :] = prediction\n",
    "            \n",
    "            # Teacher forcing\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = prediction.argmax(1).unsqueeze(1)\n",
    "            decoder_input = tgt[:, t].unsqueeze(1) if teacher_force else top1\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4007c696",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# 3. HUẤN LUYỆN\n",
    "# ============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49dab472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, criterion, clip, device):\n",
    "    \"\"\"Huấn luyện 1 epoch\"\"\"\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for src, src_lengths, tgt in dataloader:\n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        output = model(src, src_lengths, tgt, teacher_forcing_ratio=0.5)\n",
    "        \n",
    "        # output: (batch, tgt_len, vocab_size)\n",
    "        # tgt: (batch, tgt_len)\n",
    "        \n",
    "        # Bỏ <sos> token và flatten\n",
    "        output = output[:, 1:, :].reshape(-1, output.shape[-1])\n",
    "        tgt = tgt[:, 1:].reshape(-1)\n",
    "        \n",
    "        # Tính loss\n",
    "        loss = criterion(output, tgt)\n",
    "        \n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    \"\"\"Đánh giá trên tập validation\"\"\"\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for src, src_lengths, tgt in dataloader:\n",
    "            src = src.to(device)\n",
    "            tgt = tgt.to(device)\n",
    "            \n",
    "            # Forward (không teacher forcing)\n",
    "            output = model(src, src_lengths, tgt, teacher_forcing_ratio=0)\n",
    "            \n",
    "            output = output[:, 1:, :].reshape(-1, output.shape[-1])\n",
    "            tgt = tgt[:, 1:].reshape(-1)\n",
    "            \n",
    "            loss = criterion(output, tgt)\n",
    "            epoch_loss += loss.item()\n",
    "    \n",
    "    return epoch_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9377802",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# 4. DỰ ĐOÁN (INFERENCE)\n",
    "# ============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "801b4f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(model, sentence, src_vocab, tgt_vocab, src_tokenizer, device, max_len=50):\n",
    "    \"\"\"\n",
    "    Dịch một câu từ tiếng Anh sang tiếng Pháp\n",
    "    \n",
    "    Args:\n",
    "        model: mô hình đã train\n",
    "        sentence: câu tiếng Anh (string)\n",
    "        src_vocab, tgt_vocab: từ điển\n",
    "        src_tokenizer: tokenizer cho tiếng Anh\n",
    "        device: cuda/cpu\n",
    "        max_len: độ dài tối đa câu dịch\n",
    "    \n",
    "    Returns:\n",
    "        translated_sentence: câu tiếng Pháp (string)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = src_tokenizer(sentence.lower())\n",
    "    tokens = [token.text for token in tokens]\n",
    "    \n",
    "    # Encode\n",
    "    indices = src_vocab.encode(tokens) + [src_vocab.eos_idx]\n",
    "    src_tensor = torch.LongTensor(indices).unsqueeze(0).to(device)  # (1, src_len)\n",
    "    src_lengths = torch.LongTensor([len(indices)])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Encoder\n",
    "        hidden, cell = model.encoder(src_tensor, src_lengths)\n",
    "        \n",
    "        # Decoder\n",
    "        decoder_input = torch.LongTensor([tgt_vocab.sos_idx]).unsqueeze(0).to(device)\n",
    "        translated_indices = []\n",
    "        \n",
    "        for _ in range(max_len):\n",
    "            prediction, hidden, cell = model.decoder(decoder_input, hidden, cell)\n",
    "            predicted_token = prediction.argmax(1).item()\n",
    "            \n",
    "            if predicted_token == tgt_vocab.eos_idx:\n",
    "                break\n",
    "            \n",
    "            translated_indices.append(predicted_token)\n",
    "            decoder_input = torch.LongTensor([predicted_token]).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Decode\n",
    "    translated_tokens = tgt_vocab.decode(translated_indices)\n",
    "    translated_sentence = ' '.join(translated_tokens)\n",
    "    \n",
    "    return translated_sentence\n",
    "\n",
    "\n",
    "def calculate_bleu(model, test_data, src_vocab, tgt_vocab, src_tokenizer, device):\n",
    "    \"\"\"Tính BLEU score trên tập test\"\"\"\n",
    "    bleu_scores = []\n",
    "    smoothing = SmoothingFunction().method1\n",
    "    \n",
    "    for src_sent, tgt_sent in test_data:\n",
    "        src_text = ' '.join(src_sent)\n",
    "        translated = translate_sentence(model, src_text, src_vocab, tgt_vocab, src_tokenizer, device)\n",
    "        \n",
    "        reference = [tgt_sent]\n",
    "        candidate = translated.split()\n",
    "        \n",
    "        score = sentence_bleu(reference, candidate, smoothing_function=smoothing)\n",
    "        bleu_scores.append(score)\n",
    "    \n",
    "    return np.mean(bleu_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce7a31f",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# 5. MAIN - SỬ DỤNG\n",
    "# ============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d113f40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Hàm chính - ví dụ sử dụng\"\"\"\n",
    "    \n",
    "    # Cấu hình\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Hyperparameters\n",
    "    EMBEDDING_DIM = 256\n",
    "    HIDDEN_SIZE = 512\n",
    "    NUM_LAYERS = 2\n",
    "    DROPOUT = 0.5\n",
    "    LEARNING_RATE = 0.001\n",
    "    BATCH_SIZE = 64\n",
    "    NUM_EPOCHS = 10\n",
    "    CLIP = 1\n",
    "    \n",
    "    # TODO: Load dữ liệu từ file\n",
    "    # train_en, train_fr = load_data('train.en', 'train.fr')\n",
    "    # val_en, val_fr = load_data('val.en', 'val.fr')\n",
    "    # test_en, test_fr = load_data('test.en', 'test.fr')\n",
    "    \n",
    "    # TODO: Tokenize\n",
    "    # en_tokenizer = spacy.load('en_core_web_sm')\n",
    "    # fr_tokenizer = spacy.load('fr_core_news_sm')\n",
    "    \n",
    "    # TODO: Build vocabularies\n",
    "    # src_vocab = Vocabulary(max_vocab_size=10000)\n",
    "    # src_vocab.build_vocab(train_en_tokenized)\n",
    "    # tgt_vocab = Vocabulary(max_vocab_size=10000)\n",
    "    # tgt_vocab.build_vocab(train_fr_tokenized)\n",
    "    \n",
    "    # TODO: Tạo datasets và dataloaders\n",
    "    # train_dataset = TranslationDataset(train_en, train_fr, src_vocab, tgt_vocab)\n",
    "    # train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, \n",
    "    #                           shuffle=True, collate_fn=collate_fn)\n",
    "    \n",
    "    # Khởi tạo mô hình\n",
    "    encoder = Encoder(len(src_vocab), EMBEDDING_DIM, HIDDEN_SIZE, NUM_LAYERS, DROPOUT)\n",
    "    decoder = Decoder(len(tgt_vocab), EMBEDDING_DIM, HIDDEN_SIZE, NUM_LAYERS, DROPOUT)\n",
    "    model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "    \n",
    "    # Optimizer và loss\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=src_vocab.pad_idx)\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 3\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, criterion, CLIP, device)\n",
    "        val_loss = evaluate(model, val_loader, criterion, device)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{NUM_EPOCHS}')\n",
    "        print(f'Train Loss: {train_loss:.3f} | Val Loss: {val_loss:.3f}')\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "    \n",
    "    # Đánh giá BLEU\n",
    "    bleu_score = calculate_bleu(model, test_data, src_vocab, tgt_vocab, en_tokenizer, device)\n",
    "    print(f'BLEU Score: {bleu_score:.4f}')\n",
    "    \n",
    "    # Ví dụ dịch\n",
    "    sentence = \"A man is riding a horse.\"\n",
    "    translation = translate_sentence(model, sentence, src_vocab, tgt_vocab, en_tokenizer, device)\n",
    "    print(f'English: {sentence}')\n",
    "    print(f'French: {translation}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "376805f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'src_vocab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     15\u001b[39m CLIP = \u001b[32m1\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# TODO: Load dữ liệu từ file\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# train_en, train_fr = load_data('train.en', 'train.fr')\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# val_en, val_fr = load_data('val.en', 'val.fr')\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     36\u001b[39m \n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# Khởi tạo mô hình\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m encoder = Encoder(\u001b[38;5;28mlen\u001b[39m(\u001b[43msrc_vocab\u001b[49m), EMBEDDING_DIM, HIDDEN_SIZE, NUM_LAYERS, DROPOUT)\n\u001b[32m     39\u001b[39m decoder = Decoder(\u001b[38;5;28mlen\u001b[39m(tgt_vocab), EMBEDDING_DIM, HIDDEN_SIZE, NUM_LAYERS, DROPOUT)\n\u001b[32m     40\u001b[39m model = Seq2Seq(encoder, decoder, device).to(device)\n",
      "\u001b[31mNameError\u001b[39m: name 'src_vocab' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
